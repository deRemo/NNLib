{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network import NeuralNetwork\n",
    "from sgd import SGD\n",
    "from quickprop import Quickprop\n",
    "from rprop import Rprop\n",
    "from lr_schedulers import ExponentialDecayScheduler, TimeBasedScheduler, StepDecayScheduler\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "#MONK1 PROBLEM\n",
    "\n",
    "train_set = np.genfromtxt(\"../cup/ML-CUP18-TR.csv\", delimiter=\",\")[:, 1:-2]\n",
    "train_targets = np.genfromtxt(\"../cup/ML-CUP18-TR.csv\", delimiter=\",\")[:, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss at epoch  1  =  [46.67940844]\n",
      "Loss improved at epoch  1 :  [46.67940844]\n",
      "Validation loss at epoch  2  =  [22.28257937]\n",
      "Loss improved at epoch  2 :  [22.28257937]\n",
      "Validation loss at epoch  3  =  [21.42095532]\n",
      "Loss improved at epoch  3 :  [21.42095532]\n",
      "Validation loss at epoch  4  =  [22.78335263]\n",
      "Validation loss at epoch  5  =  [19.86311936]\n",
      "Loss improved at epoch  5 :  [19.86311936]\n",
      "Validation loss at epoch  6  =  [21.28151346]\n",
      "Validation loss at epoch  7  =  [18.59197408]\n",
      "Loss improved at epoch  7 :  [18.59197408]\n",
      "Validation loss at epoch  8  =  [21.48955236]\n",
      "Validation loss at epoch  9  =  [16.27120692]\n",
      "Loss improved at epoch  9 :  [16.27120692]\n",
      "Validation loss at epoch  10  =  [16.02781343]\n",
      "Loss improved at epoch  10 :  [16.02781343]\n",
      "Validation loss at epoch  11  =  [14.67332504]\n",
      "Loss improved at epoch  11 :  [14.67332504]\n",
      "Validation loss at epoch  12  =  [13.56390855]\n",
      "Loss improved at epoch  12 :  [13.56390855]\n",
      "Validation loss at epoch  13  =  [16.93311909]\n",
      "Validation loss at epoch  14  =  [20.97333931]\n",
      "Validation loss at epoch  15  =  [28.58512494]\n",
      "Validation loss at epoch  16  =  [32.31546874]\n",
      "Validation loss at epoch  17  =  [42.75841105]\n",
      "Validation loss at epoch  18  =  [48.33786366]\n",
      "Validation loss at epoch  19  =  [55.75355107]\n",
      "Validation loss at epoch  20  =  [71.99335014]\n",
      "Validation loss at epoch  21  =  [98.15971444]\n",
      "Validation loss at epoch  22  =  [125.35334344]\n",
      "Validation loss at epoch  23  =  [167.79592065]\n",
      "Validation loss at epoch  24  =  [220.55289198]\n",
      "Validation loss at epoch  25  =  [263.30399223]\n",
      "Validation loss at epoch  26  =  [339.96207416]\n",
      "Validation loss at epoch  27  =  [447.4899387]\n",
      "Validation loss at epoch  28  =  [508.13234474]\n",
      "Validation loss at epoch  29  =  [648.01521217]\n",
      "Validation loss at epoch  30  =  [773.32886301]\n",
      "Validation loss at epoch  31  =  [884.77087061]\n",
      "Validation loss at epoch  32  =  [1076.19214435]\n",
      "Validation loss at epoch  33  =  [1361.7200107]\n",
      "Validation loss at epoch  34  =  [1661.91214583]\n",
      "Validation loss at epoch  35  =  [1950.38141325]\n",
      "Validation loss at epoch  36  =  [3404.82886067]\n",
      "Validation loss at epoch  37  =  [1317.49107801]\n",
      "Validation loss at epoch  38  =  [173.06192852]\n",
      "Validation loss at epoch  39  =  [2351.48128775]\n",
      "Validation loss at epoch  40  =  [3392.7870291]\n",
      "Validation loss at epoch  41  =  [1058.13327387]\n",
      "Validation loss at epoch  42  =  [343.11145907]\n",
      "Validation loss at epoch  43  =  [2659.15745184]\n",
      "Validation loss at epoch  44  =  [2945.79936591]\n",
      "Validation loss at epoch  45  =  [658.23546669]\n",
      "Validation loss at epoch  46  =  [671.89291748]\n",
      "Validation loss at epoch  47  =  [3029.15579558]\n",
      "Validation loss at epoch  48  =  [2668.77717714]\n",
      "Validation loss at epoch  49  =  [277.50906319]\n",
      "Validation loss at epoch  50  =  [1022.7364321]\n",
      "Validation loss at epoch  51  =  [3144.460642]\n",
      "Validation loss at epoch  52  =  [1937.27438574]\n",
      "Validation loss at epoch  53  =  [49.54841596]\n",
      "Validation loss at epoch  54  =  [1750.39149499]\n",
      "Validation loss at epoch  55  =  [3223.6569857]\n",
      "Validation loss at epoch  56  =  [1239.47539491]\n",
      "Validation loss at epoch  57  =  [156.65503234]\n",
      "Validation loss at epoch  58  =  [2388.18160172]\n",
      "Validation loss at epoch  59  =  [2953.32841924]\n",
      "Validation loss at epoch  60  =  [625.00267064]\n",
      "Validation loss at epoch  61  =  [611.41262924]\n",
      "Validation loss at epoch  62  =  [3004.56864767]\n",
      "Validation loss at epoch  63  =  [2371.37755828]\n",
      "Validation loss at epoch  64  =  [127.45132015]\n",
      "Validation loss at epoch  65  =  [1342.20793279]\n",
      "Validation loss at epoch  66  =  [3325.15843159]\n",
      "Validation loss at epoch  67  =  [1592.01335558]\n",
      "Validation loss at epoch  68  =  [47.58850352]\n",
      "Validation loss at epoch  69  =  [2078.95787638]\n",
      "Validation loss at epoch  70  =  [3222.27391614]\n",
      "Validation loss at epoch  71  =  [129.67847144]\n",
      "Validation loss at epoch  72  =  [3221.72928667]\n",
      "Validation loss at epoch  73  =  [97.22384628]\n",
      "Validation loss at epoch  74  =  [3329.70185068]\n",
      "Validation loss at epoch  75  =  [78.8629138]\n",
      "Validation loss at epoch  76  =  [3216.94886376]\n",
      "Validation loss at epoch  77  =  [66.28430134]\n",
      "Validation loss at epoch  78  =  [2969.89149856]\n",
      "Validation loss at epoch  79  =  [56.58688295]\n",
      "Validation loss at epoch  80  =  [2861.48957105]\n",
      "Validation loss at epoch  81  =  [70.37232809]\n",
      "Validation loss at epoch  82  =  [2808.35500909]\n",
      "Validation loss at epoch  83  =  [114.85767229]\n",
      "Validation loss at epoch  84  =  [2787.79797776]\n",
      "Validation loss at epoch  85  =  [237.03413056]\n",
      "Validation loss at epoch  86  =  [2676.36565963]\n",
      "Validation loss at epoch  87  =  [416.36748487]\n",
      "Validation loss at epoch  88  =  [2481.64508027]\n",
      "Validation loss at epoch  89  =  [681.2740586]\n",
      "Validation loss at epoch  90  =  [2365.90314081]\n",
      "Validation loss at epoch  91  =  [908.84068056]\n",
      "Validation loss at epoch  92  =  [2028.6644891]\n",
      "Validation loss at epoch  93  =  [1293.20789619]\n",
      "Validation loss at epoch  94  =  [1715.25433051]\n",
      "Validation loss at epoch  95  =  [1609.77776635]\n",
      "Validation loss at epoch  96  =  [1241.55457028]\n",
      "Validation loss at epoch  97  =  [2118.87163462]\n",
      "Validation loss at epoch  98  =  [814.29708606]\n",
      "Validation loss at epoch  99  =  [2541.57197747]\n",
      "Validation loss at epoch  100  =  [409.41309005]\n",
      "Validation loss at epoch  101  =  [2853.88706491]\n",
      "Validation loss at epoch  102  =  [136.18799317]\n",
      "Validation loss at epoch  103  =  [3052.73874426]\n",
      "Validation loss at epoch  104  =  [24.97403988]\n",
      "Validation loss at epoch  105  =  [3085.75279085]\n",
      "Validation loss at epoch  106  =  [386.01639219]\n",
      "Validation loss at epoch  107  =  [1629.08143381]\n",
      "Validation loss at epoch  108  =  [2536.19862248]\n",
      "Validation loss at epoch  109  =  [30.27500197]\n",
      "Validation loss at epoch  110  =  [2616.9190885]\n",
      "Validation loss at epoch  111  =  [1660.92137677]\n",
      "Validation loss at epoch  112  =  [372.83390056]\n",
      "Validation loss at epoch  113  =  [2996.52053752]\n",
      "Validation loss at epoch  114  =  [632.23878235]\n",
      "Validation loss at epoch  115  =  [1296.80303579]\n",
      "Validation loss at epoch  116  =  [2836.89321573]\n",
      "Validation loss at epoch  117  =  [79.68365413]\n",
      "Validation loss at epoch  118  =  [2233.77158661]\n",
      "Validation loss at epoch  119  =  [1964.01174335]\n",
      "Validation loss at epoch  120  =  [180.64400578]\n",
      "Validation loss at epoch  121  =  [2934.12313951]\n",
      "Validation loss at epoch  122  =  [974.8494973]\n",
      "Validation loss at epoch  123  =  [893.99772228]\n",
      "Validation loss at epoch  124  =  [2959.72270787]\n",
      "Validation loss at epoch  125  =  [219.55510214]\n",
      "Validation loss at epoch  126  =  [1915.11099374]\n",
      "Validation loss at epoch  127  =  [2342.36968473]\n",
      "Validation loss at epoch  128  =  [59.28637393]\n",
      "Validation loss at epoch  129  =  [2739.77549847]\n",
      "Validation loss at epoch  130  =  [1354.74002925]\n",
      "Validation loss at epoch  131  =  [552.61134068]\n",
      "Validation loss at epoch  132  =  [3030.78986708]\n",
      "Validation loss at epoch  133  =  [469.85436498]\n",
      "Validation loss at epoch  134  =  [1434.4250406]\n",
      "Validation loss at epoch  135  =  [2627.34392036]\n",
      "Validation loss at epoch  136  =  [37.99801141]\n",
      "Validation loss at epoch  137  =  [2411.88253206]\n",
      "Validation loss at epoch  138  =  [1871.3324684]\n",
      "Validation loss at epoch  139  =  [229.30480268]\n",
      "Validation loss at epoch  140  =  [2926.3477168]\n",
      "Validation loss at epoch  141  =  [1710.79147937]\n",
      "Validation loss at epoch  142  =  [34.19945292]\n",
      "Validation loss at epoch  143  =  [1480.52949863]\n",
      "Validation loss at epoch  144  =  [3010.624022]\n",
      "Validation loss at epoch  145  =  [1390.52585951]\n",
      "Validation loss at epoch  146  =  [36.64486915]\n",
      "Validation loss at epoch  147  =  [1766.07385171]\n",
      "Validation loss at epoch  148  =  [2892.8886228]\n",
      "Validation loss at epoch  149  =  [1026.25384949]\n",
      "Validation loss at epoch  150  =  [128.19986065]\n",
      "Validation loss at epoch  151  =  [2114.74556467]\n",
      "Validation loss at epoch  152  =  [2792.99504171]\n",
      "Validation loss at epoch  153  =  [734.3896098]\n",
      "Validation loss at epoch  154  =  [286.96198477]\n",
      "Validation loss at epoch  155  =  [2392.34198129]\n",
      "Validation loss at epoch  156  =  [2593.83900754]\n",
      "Validation loss at epoch  157  =  [468.19614784]\n",
      "Validation loss at epoch  158  =  [511.27877615]\n",
      "Validation loss at epoch  159  =  [2629.50089792]\n",
      "Validation loss at epoch  160  =  [2336.0209286]\n",
      "Validation loss at epoch  161  =  [250.70397869]\n",
      "Validation loss at epoch  162  =  [779.27648698]\n",
      "Validation loss at epoch  163  =  [2791.96485025]\n",
      "Validation loss at epoch  164  =  [2030.4492771]\n",
      "Validation loss at epoch  165  =  [99.90130571]\n",
      "Validation loss at epoch  166  =  [1091.84047825]\n",
      "Validation loss at epoch  167  =  [2926.95425897]\n",
      "Validation loss at epoch  168  =  [1733.9941646]\n",
      "Validation loss at epoch  169  =  [30.97978811]\n",
      "Validation loss at epoch  170  =  [1404.52388936]\n",
      "Validation loss at epoch  171  =  [2925.63381271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss at epoch  172  =  [1368.64670541]\n",
      "Validation loss at epoch  173  =  [40.22912604]\n",
      "Validation loss at epoch  174  =  [1774.39413868]\n",
      "Validation loss at epoch  175  =  [2936.872822]\n",
      "Validation loss at epoch  176  =  [1861.90927339]\n",
      "Validation loss at epoch  177  =  [353.40470019]\n",
      "Validation loss at epoch  178  =  [179.49743775]\n",
      "Validation loss at epoch  179  =  [1525.68699406]\n",
      "Validation loss at epoch  180  =  [2789.5096173]\n",
      "Validation loss at epoch  181  =  [2473.7446028]\n",
      "Validation loss at epoch  182  =  [949.48007316]\n",
      "Validation loss at epoch  183  =  [23.88132757]\n",
      "Validation loss at epoch  184  =  [796.20653833]\n",
      "Validation loss at epoch  185  =  [2360.52922916]\n",
      "Validation loss at epoch  186  =  [2870.85945768]\n",
      "Validation loss at epoch  187  =  [1727.27263634]\n",
      "Validation loss at epoch  188  =  [274.93355465]\n",
      "Validation loss at epoch  189  =  [226.0894915]\n",
      "Validation loss at epoch  190  =  [1631.60251323]\n",
      "Validation loss at epoch  191  =  [2826.26712324]\n",
      "Validation loss at epoch  192  =  [2407.87037383]\n",
      "Validation loss at epoch  193  =  [863.38144892]\n",
      "Validation loss at epoch  194  =  [21.79358554]\n",
      "Validation loss at epoch  195  =  [869.9831338]\n",
      "Validation loss at epoch  196  =  [2404.99962153]\n",
      "Validation loss at epoch  197  =  [2811.06102926]\n",
      "Validation loss at epoch  198  =  [1608.34955971]\n",
      "Validation loss at epoch  199  =  [221.50440715]\n",
      "Validation loss at epoch  200  =  [291.96999588]\n",
      "Validation loss at epoch  201  =  [1740.49969831]\n",
      "Validation loss at epoch  202  =  [2866.13058607]\n",
      "Validation loss at epoch  203  =  [2336.12006217]\n",
      "Validation loss at epoch  204  =  [779.70352302]\n",
      "Validation loss at epoch  205  =  [27.20281309]\n",
      "Validation loss at epoch  206  =  [953.51916632]\n",
      "Validation loss at epoch  207  =  [2459.4303349]\n",
      "Validation loss at epoch  208  =  [2761.25641964]\n",
      "Validation loss at epoch  209  =  [1503.3129437]\n",
      "Validation loss at epoch  210  =  [170.24268198]\n",
      "Validation loss at epoch  211  =  [28.33559259]\n",
      "Validation loss at epoch  212  =  [344.08324388]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<neural_network.NeuralNetwork at 0x16f03d1a860>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NeuralNetwork()\n",
    "nn.add_layer('dense', 20, 'sigmoid', train_set.shape[1]) #input layer\n",
    "nn.add_layer('dense', 20, 'sigmoid')\n",
    "nn.add_layer('dense', 2, 'linear')\n",
    "nn.compile(task='Regression', l2_lambda=1e-4, optimizer=SGD(lr_init=0.001, momentum=0, lr_sched=StepDecayScheduler(drop=0.5, epochs_drop=35)))\n",
    "\n",
    "nn.fit(train_set, train_targets, batch_size=256, test_size=0.3, epochs=5000, patience=200, save_stats=None, save_model=None, debug=True, verbose=True) #lr=0.05 test_size=0.5 epochs=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prediction = nn.predict(test_set)\n",
    "accuracy_score(test_targets, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MONK2 PROBLEM\n",
    "\n",
    "train_set = np.genfromtxt(\"../monks/monks2-train.txt\", delimiter=\" \", dtype=\"int\")[:,1:-1] #rimuove la colonna nan alla fine\n",
    "train_targets = np.genfromtxt(\"../monks/monks2-train.txt\", delimiter=\" \", dtype=\"int\")[:,:1]\n",
    "\n",
    "test_set = np.genfromtxt(\"../monks/monks2-test.txt\", delimiter=\" \", dtype=\"int\") [:,1:-1] #rimuove targets e colonna nan \n",
    "test_targets = np.genfromtxt(\"../monks/monks2-test.txt\", delimiter=\" \", dtype=\"int\") [:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy improved at epoch  1 :  0.6190476190476191\n",
      "Accuracy improved at epoch  3 :  0.6309523809523809\n",
      "Accuracy improved at epoch  35 :  0.6428571428571429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<neural_network.NeuralNetwork at 0x1c1e6629550>"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NeuralNetwork()\n",
    "nn.add_layer('dense', 10, 'sigmoid', train_set.shape[1]) #input layer\n",
    "nn.add_layer('dense', 10, 'sigmoid') #input layer\n",
    "nn.add_layer('dense', 1, 'sigmoid')\n",
    "nn.compile(optimizer=SGD(lr_init=0.1, momentum=0.8, nesterov=False, lr_sched=StepDecayScheduler(drop=0.9, epochs_drop=10)))\n",
    "\n",
    "nn.fit(train_set, train_targets, batch_size=16, test_size=0.5, epochs=5000, patience=200, save_model='best_nn_monk2_tmp', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7291666666666666"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = nn.predict(test_set)\n",
    "accuracy_score(test_targets, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MONK3 PROBLEM\n",
    "\n",
    "train_set = np.genfromtxt(\"../monks/monks3-train.txt\", delimiter=\" \", dtype=\"int\")[:,1:-1] #rimuove la colonna nan alla fine\n",
    "train_targets = np.genfromtxt(\"../monks/monks3-train.txt\", delimiter=\" \", dtype=\"int\")[:,:1]\n",
    "\n",
    "test_set = np.genfromtxt(\"../monks/monks3-test.txt\", delimiter=\" \", dtype=\"int\") [:,1:-1] #rimuove targets e colonna nan \n",
    "test_targets = np.genfromtxt(\"../monks/monks3-test.txt\", delimiter=\" \", dtype=\"int\") [:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy improved at epoch  1 :  0.5081967213114754\n",
      "Accuracy improved at epoch  2 :  0.7213114754098361\n",
      "Accuracy improved at epoch  3 :  0.8032786885245902\n",
      "Accuracy improved at epoch  6 :  0.8852459016393442\n",
      "Accuracy improved at epoch  14 :  0.9016393442622951\n",
      "Accuracy improved at epoch  15 :  0.9344262295081968\n",
      "Accuracy improved at epoch  30 :  0.9508196721311475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<neural_network.NeuralNetwork at 0x1c1e6604860>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NeuralNetwork()\n",
    "nn.add_layer('dense', 40, 'sigmoid', train_set.shape[1]) #input layer\n",
    "nn.add_layer('dense', 30, 'sigmoid') #input layer\n",
    "nn.add_layer('dense', 1, 'sigmoid')\n",
    "nn.compile(optimizer=SGD(lr_init=0.25, momentum=0.8, nesterov=False, lr_sched=StepDecayScheduler(drop=0.1, epochs_drop=15)))\n",
    "\n",
    "nn.fit(train_set, train_targets, batch_size=16, test_size=0.5, epochs=5000, patience=200, save_model='best_nn_monk3_tmp', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8680555555555556"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = nn.predict(test_set)\n",
    "accuracy_score(test_targets, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
